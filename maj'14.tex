\documentclass[oneside,30pt]{article}
\usepackage{polski}
\usepackage[cp1250]{inputenc}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{setspace}
\usepackage[margin=60px]{geometry}

\begin{document}
%\doublespacing
%\LARGE
\section{Wprowadzenie}
W coraz liczniejszej grupie algorytmów populacyjnych w ostatnim czasie coraz wiêksz¹ rolê odgrywaæ zaczynaj¹ algorytmy wykorzystuj¹ce modele probabilistyczne.

S¹ to najczêœciej metody o strukturze bardzo podobnej do struktury algorytmu ewolucyjnego, z t¹ ró¿nic¹, ¿e kolejne pokolenia osobników/rozwi¹zañ generuje siê na bazie modelu probabilistycznego populacji rozwi¹zañ obiecuj¹cych, nie zaœ jako efekt krzy¿owania b¹dŸ mutacji osobników z populacji bie¿¹cej.

\section{Przegl¹d literatury}

W pracy zaprezentowane zostan¹ dwie wersje algorytmów z modelem probabilistycznym PBIL (\textit{ang. Population-based incremental learning })oraz cGA (\textit{ang. Compact Genetic Algorithm}). Obie metody s¹ neurystykami populacyjnymi, które rozwa¿aj¹ populacjê w procesie iteracyjnym.
\section{PBIL}
Pierwszym z prezentowanych algorytmów jest algorytm wykorzystuj¹cy proces uczenia oparty na ,,obserwacji" populacji, tzw PBIL (\textit{ang. Population-based incremental learning}). 

W metodzie tej osobniki kolejnych populacji tworzone s¹ na podstawie wektora $\mathbf{p}=
\left[p_1,p_2,\ldots, p_m \right]$, którego sk³adowe $p_i$ okreœlaj¹ prawdopodobieñstwo wyst¹pienia jedynki na 
i-tej pozycji generowanego osobnika.

Na pocz¹tku procesu ustala siê, ¿e sk³adowe wektora \textbf{p} maj¹ jednakow¹, równ¹ $\frac{1}{2}$ wartoœæ.

Z rozk³adem równomiernym losuje siê tak¿e populacjê startow¹ (jako zbiór ci¹gów 0--1 d³ugoœci $m$).

Charakterystyczne dla algorytmu PBIL jest wykorzystanie do uaktualnienia wektora \textbf{p} wy³¹cznie najlepszego osobnika w pokoleniu bie¿¹cym. Oznacza to, ¿e model probabilistyczny powstaje w oparciu o jednego, najbardziej obiecuj¹cego osobnika, oznaczanego~\textbf{b}.

Sk³adowe wektora \textbf{p} uaktualnia siê w kolejnych pokoleniach wed³ug wzoru:
\begin{equation}
p_i^{(k+1)} = (1-\lambda )\cdot p_i^{(k)} + \lambda b_i,
\end{equation}
gdzie $p_i^{(k)}$ to i-ta sk³adowa wektora \textbf{p} w pokoleniu k, $b_i$ -- sk³adowa \textbf{b}, a $\lambda$--wspó³czynnik uczenia.

Osobniki populacji $k+1$ losowane s¹ z uwzglêdnieniem nowego wektora prawdopodobieñstw. W~przeciwieñstwie do standardowego algorytmu genetycznego, PBIL nie zachowuje najlepszego osobnika w populacji, ale procedura daje ogromne szanse na jego wylosowanie, gdy¿ w³aœnie na jego podstawie modyfikowany jest wektor prawdopodobieñstwa. Losowanie ca³ej populacji, uwzglêdniaj¹ce model (reprezentowany przez \textbf{p}) daje spore szanse na pojawienie siê wiêkszej liczby dobrych osobników (lepszych ni¿ w poprzedniej generacji).\\
Pseudokod PBIL:
\begin{enumerate}
\item Losowanie populacji startowej, zainicjowanie wektora prawdopodobieñstw 
$$\mathbf{p},\; (p_i =0.5, \forall i=1,\ldots,n)$$
\item Ocena osobników, wybór najlepszego wektora \textbf{b}.
\item Obliczenie wektora prawdopodobieñstw wed³ug wzoru
\begin{equation}
\nonumber
p_i = (1-\lambda )\cdot p_i + \lambda \cdot b_i,
\end{equation}
gdzie $\lambda\text{ -- wspó³czynnik uczenia}$
\item Wylosowanie nowej populacji zgodnie z modelem (z uwzglêdnieniem \textbf{p}) 
\item Sprawdzenie warunku zatrzymania, jeœli spe³niony -- zakoñczenie algorytmu, w przeciwnym razie powrót do 2.
\end{enumerate}\newpage
\section{cGA}
Kolejnym algorytmem, bazuj¹cym na algorytmie genetycznym i wykorzystuj¹cym model probabilistyczny jest algorytm cGA(\textit{ang. Compact Genetic Algorithm}).

Podobnie jak w PBIL, kolejne pokolenia osobników tworzone s¹ w oparciu o model probabilistyczny. Model budowany jest tak¿e w oparciu o rozwi¹zania z pokolenia bie¿¹cego, przy czym w jego konstrukcji rolê odgrywa zarówno najlepszy, jak i najgorszy osobnik. Rolê modelu ponownie pe³ni wektor prawdopodobieñstw \textbf{p}, którego sk³adowe wyznacza siê wed³ug wzoru:
\begin{equation}
{p_i} = \left\{\begin{array}{l l}
p_i+\frac{1}{m}, & x_i=1 \land y_i = 0\\[0.3 em]
p_i-\frac{1}{m}, & x_i=0 \land y_i = 1\\[0.3 em]
p_i, & \text{pozosta³e}
\end{array}\right.
\label{eq:2}
\end{equation}
gdzie \begin{itemize}\item[]$X=\left[x_1, \ldots, x_m \right]$-- najlepszy osobnik
\item[]$Y=\left[y_1, \ldots, y_m \right] $-- najgorszy osobnik
\item $m$ -- liczebnoœæ populacji
\end{itemize}

Sk³adowe wektora\textbf{p} okreœlaj¹ prawdopodobieñstwo wystêpowania $1$ na i-tym miejscu osobnika generowanego do kolejnej populacji. Wspó³czynnik $\frac{1}{m}$ pe³ni we wzorze \eqref{eq:2} rolê wspó³czynnika uczenia siê i mo¿e byæ zast¹piony dowoln¹ ustalon¹ wielkoœci¹. Algorytm ten pozwala efektywniej tworzyæ wektor prawdopodobieñstw dziêki wykorzystaniu najlepszego i najgorszego osobnika. Przez ten zabieg szansa wylosowania osobnika zbli¿onego do najlepszego roœnie, a najgorszego maleje o ustalon¹ wartoœæ. Schemat algorytmu zaprezentowano poni¿ej w formie pseudokodu.

\begin{enumerate}
\item Losowanie populacji startowej, zainicjowanie wektora prawdopodobieñstw \textbf{p} (wszystkie wartoœci $p_i = 0.5, i= 1, \ldots, n$).
\item Ocena osobników, wybór najlepszego i najgorszego (porównanie z najlepszym i najgorszym z poprzedniej populacji).
\item Obliczenie wektora prawdopodobieñstw wed³ug wzoru
\begin{equation}
\nonumber
{p_i} = \left\{\begin{array}{l l}
p_i+\frac{1}{m}, & x_i=1 \land y_i = 0\\[0.3 em]
p_i-\frac{1}{m}, & x_i=0 \land y_i = 1\\[0.3 em]
p_i, & \text{pozosta³e}
\end{array}\right.
\end{equation}
\item Wygenerowanie nowej populacji z uwzglêdnieniem prawdopodobieñstw \textbf{p}
\item Sprawdzenie warunku zatrzymania, jeœli spe³niony -- zakoñczenie algorytmu, w przeciwnym razie 2.
\end{enumerate}
\section{Opis zadañ testowych}
\subsection{$Trap_n$} Rozwa¿ane s¹ wektory d³ugoœci $n$. Rozwi¹zaniem problemu jest znalezienie maksymalnej wartoœci funkcji $trap$ rzêdu $n$--tego, czyli wektora, który na ka¿dej pozycji ma wartoœæ 1. Funkcja opisana jest wzorem:
$$f_{trap_n}(u)=\left\{\begin{array}{l l}
n-1-u_1, & \text{dla } u_1 < n \\[0.3 em]
n, & \text{w pozosta³ych przypadkach}\\[0.3 em]
\end{array}\right., $$
gdzie $n$--dany rz¹d funkcji,\\
$u_1$--iloœæ jedynek w wejœciowym ci¹gu.\\
Przyk³adowo, funkcja $trap_5$ bêdzie wyra¿ona wzorem:
$$f_{trap_5}(u)=\left\{\begin{array}{l l}
4-u_1, & \text{dla } u_1 < 5 \\[0.3 em]
5, & \text{w pozosta³ych przypadkach}\\[0.3 em]
\end{array}\right., $$
%TODO wykres
\subsection{3-deceptive} Problemem jest znalezienie maksimum globalnego funkcji, która posiada dwa maxima lokalne i jedno minimum. \\
Funkcjê 3-deceptive mo¿na zapisaæ wzorem:
$$f_{3deceptive}(u)=\left\{\begin{array}{l l}
0.9, & \text{dla } u_1 = 0 \\[0.3 em]
0.8, & \text{dla } u_1 = 1\\[0.3 em]
0, & \text{dla } u_1 = 2\\[0.3 em]
1, & \text{w pozosta³ych przypadkach}\\[0.3 em]
\end{array}\right., $$
gdzie $u_1$-- iloœæ wspó³rzêdnych, na których przyjmowana jest wartoœæ 1.
%TODO wykres
\subsection{Max diversity} Badanym zagadnieniem s¹ odleg³oœci punktów z zadanego zbioru $X$ przestrzeni $n$-wymiarowej. Celem jest wybranie spoœród nich $m$--elementowego podzbioru, których suma wzajemnych odleg³oœci jest najwiêksza.\\
Zadawany jest wyjœciowy zbiór punktów oraz liczba punktów, z których z³o¿ony jest szukany podzbiór.\\
Przyk³adowo, rozwa¿aj¹c zbiór wierzcho³ków jednostkowego kwadratu, zaczepionego w pocz¹tku uk³adu wspó³rzêdnych i szukaj¹c maksymalnej odleg³oœci miêdzy dwoma punktami, powinniœmy otrzymaæ dwa wierzcho³ki, których odleg³oœæ wynosi $\sqrt{2}$.\\
W rozwa¿anym problemie, przyjmowaæ bêdziemy standardow¹ odleg³oœæ Euklidesow¹:
$$d(X,Y)=\sqrt{\sum_{i=1}^n \left( x_i - y_i\right)^2},$$
gdzie $X = (x_1,\, x_2, \ldots, x_n)$, $Y = (y_1,\, y_2, \ldots, y_n)$ ~--punkty z zadanego zbioru.\\
Aby sprowadziæ funkcjê do postaci w jakiej rozwa¿amy algorytm \textit{PBIL}, mo¿emy zapisaæ j¹ wzorem:
$$\text{MD}(A,X)= \sum_{i=1}^{n-1} \sum_{j=i+1} ^{n} d(X_i,X_j),$$
gdzie $A=\{X_1,\,X_2 \ldots X_m\}$ -- $m$-elementowy podzbiór $X$,
\newpage
%---------------------------------------------------------------%
\section{Wyniki testów}
Podane wyniki s¹ uœrednion¹ wartoœci¹ uzyskan¹ ze 100 eksperymentów.
%---------------------------------------------------------------%
\subsection{Trap}
\subsubsection{Trap 5 (Maksimum rzeczywiste = $5$)}
\begin{table}[h!]
\caption{Wyniki testów na $trap_5$}
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
 & \multicolumn{6}{|c|}{\textit{Iloœæ iteracji (b³¹d)}}\\ \cline{2-7}
&  & \multicolumn{5}{|c|}{\textit{PBIL}} \\ \cline{3-7}
\textbf{Liczebnoœæ populacji} &CGA &    $\lambda = 0.5$ &$\lambda = 0.2$ &$\lambda = 0.1$ &$\lambda = 0.01$ &$\lambda = 0.0001$  \\\hline\hline
5 &4.06 &24.62(0.58)&6.03(0.04)&\textbf{3.94(0.)}     &5.94(0.)   & 6.77(0.)   \\\hline
 20 &\textbf{1.02} &1.63(0.) &1.59(0.) & 1.88(0.)    &  2.02(0.) &  2.6(0.)  \\\hline
 50&1.00 &1.2(0.) & 1.18(0.)   & 1.21(0.)    & 1.32(0.)  & 1.21(0.)   \\\hline
 \end{tabular}
 \end{table}
 
\subsubsection{Trap 6 (Maksimum rzeczywiste = $6$)}
\begin{table}[h!]
\caption{Wyniki testów na $trap_6$}
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
 & \multicolumn{6}{|c|}{\textit{Iloœæ iteracji (b³¹d)}}\\ \cline{2-7}
&  & \multicolumn{5}{|c|}{\textit{PBIL}} \\ \cline{3-7}
\textbf{Liczebnoœæ populacji} &CGA &    $\lambda = 0.5$ &$\lambda = 0.2$ &$\lambda = 0.1$ &$\lambda = 0.01$ &$\lambda = 0.0001$  \\\hline\hline
 5&3.22 & 47.91(1.29) &13.76(0.3)& 6.76(0.03)& 10.6  &  12.46(0.01)  \\\hline
 20&2.22 & 3.84(0.06) & 2.26     &  2.6(0.) &  3.05 &  3.44  \\\hline
 50 &1.70 & 1.423(0.) &  1.46    &  1.53    & 1.63  &  1.71  \\\hline
 100 &1.04 & 1.22(0.) &  1.25    &  1.15    & 1.19  & 1.19   \\\hline
\end{tabular}
\end{table}

\subsubsection{Trap 7(Maksimum rzeczywiste = $7$)}
\begin{table}[h!]
\caption{Wyniki testów na $trap_7$}
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
 & \multicolumn{6}{|c|}{\textit{Iloœæ iteracji(b³¹d)}}\\ \cline{2-7}
&  & \multicolumn{5}{|c|}{\textit{PBIL}} \\ \cline{3-7}
\textbf{Liczebnoœæ populacji} &CGA &    $\lambda = 0.5$ &$\lambda = 0.2$ &$\lambda = 0.1$ &$\lambda = 0.01$ &$\lambda = 0.0001$  \\\hline\hline
 5&4.92 &63.61(1.84)&  34.72(0.92)  & 19.53(.39)    &14.99   &   25.91(0.02) \\\hline
 20&3.46 & 15.71(0.41)   &  4.(0.03)  &  3.76   & 5.61  & 7.89   \\\hline
 50 &2.74 &  2.81(0.03)  &   2.06 & 2.18 &2.59   &  3.08  \\\hline
 100 &1.68 &  1.43  &  1.42  &  1.44   &  1.65 &  1.76  \\\hline
 200 &1.28 &   1.16 &  1.26  &  1.19   & 1.26  &  1.2  \\\hline
\end{tabular}
\end{table}

\subsubsection{Trap 10(Maksimum rzeczywiste = $10$)}
\begin{table}[h!]
\caption{Wyniki testów na $trap_{10}$}
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
 & \multicolumn{6}{|c|}{\textit{Iloœæ iteracji(b³¹d)}}\\[0.3 em] \cline{2-7}
&  & \multicolumn{5}{|c|}{\textit{PBIL}} \\ \cline{3-7}
\textbf{Liczebnoœæ populacji} &CGA &    $\lambda = 0.5$ &$\lambda = 0.2$ &$\lambda = 0.1$ &$\lambda = 0.01$ &$\lambda = 0.0001$  \\\hline\hline
 5&5.42 & 141.76(3.6)& 71.36(2.59) & 56.78(1.8)& 42.21(0.06)&   78.45(0.97) \\\hline
 20&6.58 & 84.58(1.97)& 30.72(0.92) & 12.78(0.18)& 20.21&  40.79(0.13)  \\\hline
 50 &6.74 & 37.64(0.77)&7.78(0.12)& 4.79 & 12.49  &  21.14(0.01)  \\\hline
 100 &5.50 & 7.94(0.12) & 2.86  & 3.85 & 7.42  &  10.82  \\\hline
 200 &5.00 &  4.78(0.06)& 2.22  & 2.79 & 4.7  & 4.88   \\\hline
 500 &2.22 &  1.79   &  1.66   & 1.69  & 2.16  & 2.28\\\hline
\end{tabular}
\end{table}
\textbf{Podsumowanie:} Metoda dzia³a lepiej, im ni¿szy rz¹d funkcji i wiêksza populacja.
\newpage

%---------------------------------------------------------------%
\subsection{3-deceptive (maksimum rzeczywiste = 1)}
\subsubsection{Wektory 3-elementowe}
\begin{table}[h!]
\caption{Wyniki testów na $3-deceptive$ dla wektorów d³.3}
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
 & \multicolumn{6}{|c|}{\textit{Iloœæ iteracji(b³¹d)}}\\ \cline{2-7}
&  & \multicolumn{5}{|c|}{\textit{PBIL}} \\ \cline{3-7}
\textbf{Liczebnoœæ populacji} &CGA &    $\lambda = 0.5$ &$\lambda = 0.2$ &$\lambda = 0.1$ &$\lambda = 0.01$ &$\lambda = 0.0001$  \\\hline\hline
 5&1.67 &   6.26(0.01)  & 1.36   &   1.84  & 1.77  &   1.89 \\\hline
 20&0.93 & 1.01   & 0.97  &  0.93  &1.07   &0.94   \\\hline
 50 &0.91 &  0.87 &0.84   &  0.86  &0.88  &  0.88 \\\hline
 100 &0.87 & 0.84  &  0.86  &0.88    &0.91  &0.83   \\\hline
 200 &0.9  & 0.86  & 0.85   &  0.85   &0.86  &0.89 \\\hline
 500 &0.92 &  0.91  &  0.86  &   0.82  & 0.93  &  0.84 \\\hline
\end{tabular}
\end{table}

\subsubsection{Wektory 5-cio elementowe}
\begin{table}[h!]
\caption{Wyniki testów na $3-deceptive$ dla wektorów d³.5}
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
 & \multicolumn{6}{|c|}{\textit{Iloœæ iteracji(b³¹d)}}\\ \cline{2-7}
&  & \multicolumn{5}{|c|}{\textit{PBIL}} \\ \cline{3-7}
\textbf{Liczebnoœæ populacji} &CGA &    $\lambda = 0.5$ &$\lambda = 0.2$ &$\lambda = 0.1$ &$\lambda = 0.01$ &$\lambda = 0.0001$  \\\hline\hline
 5&0.54 & 0.61  &0.47   & 0.53   &0.55  &0.57   \\\hline
 20&0.54 & 0.43  & 0.4  &  0.4  &0.49  &   0.61\\\hline
 50 &0.44 & 0.58  & 0.47  &0.48    &0.59  & 0.47  \\\hline
 100 &0.62 & 0.52  &0.5   & 0.48   & 0.43 & 0.48  \\\hline
 200 &0.52 &0.61   & 0.51  & 0.54   &0.5   & 0.54  \\\hline
 500 &0.46 & 0.47  & 0.46  &  0.58  &0.55  & 0.5  \\\hline
\end{tabular}
\end{table}
\subsubsection{Wektory 10-cio elementowe}
\begin{table}[h!]
\caption{Wyniki testów na $3-deceptive$ dla wektorów d³.10}
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
 & \multicolumn{6}{|c|}{\textit{Iloœæ iteracji(b³¹d)}}\\ \cline{2-7}
&  & \multicolumn{5}{|c|}{\textit{PBIL}} \\ \cline{3-7}
\textbf{Liczebnoœæ populacji} &CGA &    $\lambda = 0.5$ &$\lambda = 0.2$ &$\lambda = 0.1$ &$\lambda = 0.01$ &$\lambda = 0.0001$  \\\hline\hline  
 5&0.02  &0.02   & 0.07  &  0.05  &0.1  &  0.04 \\\hline
 20 &0.06   & 0.03  & 0.05  & 0.06   &0.07  &0.05   \\\hline
 50 &0.02   &0.05   &0.02   &    0.08& 0.02 & 0.07  \\\hline
 100 &0.04   &0.07   &  0.02 &   0.0 &0.03  & 0.1  \\\hline
 200 &0.06   & 0.06  & 0.04  &   0.07 &  0.08& 0.02  \\\hline
 500 &   & 0.03  &  0.06   &0.06  &0.04 &0.04 \\\hline
\end{tabular}
\end{table}
\textbf{Podsumowanie:} Metoda dzia³a lepiej im d³u¿y jest wektor i populacja jest bardziej liczna.
\newpage
\subsection{Max diversity}
W tym przypadku równie¿ przeprowadzone zosta³o 100 prób, lecz b³¹d bêdzie podawany w skali procentowej. Wielkoœciom odpowiadaæ bêdzie odsetek poprawnych wielkoœci.
\subsubsection{Wierzcho³ki kwadratu w przestrzeni 2-wymiarowej}
$X=\{(0,0), (0,1), (1,0), (1,1)\}$
\begin{enumerate}
\item[m=2, ] maksimum rzeczywiste = $\sqrt{2}$
\begin{table}[h!]
\caption{Wyniki testów na $Max Diversity$ dla wierzcho³ków kwadratu ($m=2$)}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}\hline
  & \multicolumn{11}{|c|}{\textit{Iloœæ iteracji}}\\ \cline{2-12}
\textbf{Liczebnoœæ} &  & \multicolumn{10}{|c|}{\textit{PBIL}} \\ \cline{3-12}
\textbf{populacji} &CGA &    \multicolumn{2}{|c|}{$\lambda = 0.5$} &\multicolumn{2}{|c|}{$\lambda = 0.2$} &\multicolumn{2}{|c|}{$\lambda = 0.1$} &\multicolumn{2}{|c|}{$\lambda = 0.01$} &\multicolumn{2}{|c|}{$\lambda = 0.0001$ } \\\hline\hline 
 3&2.03  &2.26 &95\%  & 2.14& 99\%  & 2.09&99\%  &2.00 &98\%  &  2.18 &95\% \\\hline
 5&1.89  &1.96 & 99\%   & 1.88&100\%  &  1.82&100\%  &1.84&100\%  &  1.82&100\% \\\hline
 20 &1.62   & 1.73& 100\%  & 1.69&100\%  & 1.64&100\% &1.66&100\%  &1.72&100\%   \\\hline
 50 &1.68   &1.62& 100\%    &1.65&100\%   &    1.73&100\%& 1.7&100\% & 1.7&100\%  \\\hline
 100 &1.68   &1.6& 100\%    &  1.62&100\% &   1.72&100\% &1.66&100\%  & 1.61&100\%  \\\hline
\end{tabular}
\end{table}
%\textbf{Wnioski:} 
%-------------------------------------------------%
\item[m=3, ] maksimum rzeczywiste = $2+\sqrt{2}$
\begin{table}[h!]
\caption{Wyniki testów na $Max Diversity$ dla wierzcho³ków kwadratu ($m=3$)}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}\hline
  & \multicolumn{11}{|c|}{\textit{Iloœæ iteracji}}\\ \cline{2-12}
\textbf{Liczebnoœæ} &  & \multicolumn{10}{|c|}{\textit{PBIL}} \\ \cline{3-12}
\textbf{populacji} &CGA &    \multicolumn{2}{|c|}{$\lambda = 0.5$} &\multicolumn{2}{|c|}{$\lambda = 0.2$} &\multicolumn{2}{|c|}{$\lambda = 0.1$} &\multicolumn{2}{|c|}{$\lambda = 0.01$} &\multicolumn{2}{|c|}{$\lambda = 0.0001$ } \\\hline\hline 
 3&1  &1 &100\%  & 1& 100\%  & 1&100\%  &1 &100\%  &  1 &100\% \\\hline
 5&1  &1 & 100\%   & 1&100\%  &  1&100\%  &1&100\%  &  1&100\% \\\hline
 20 &1   & 1& 100\%  & 1&100\%  & 1&100\% &1&100\%  &1&100\%   \\\hline
 50 &1   &1& 100\%    &1&100\%   &    1&100\%& 1&100\% & 1&100\%  \\\hline
 100 &1   &1& 100\%    &  1&100\% &   1&100\% &1&100\%  & 1&100\%  \\\hline
\end{tabular}
\end{table}\\
\textbf{Wnioski:} W tym przypadku ka¿dy z podzbiorów spe³nia warunki, wiêc 100\% wyników jest poprawnych, otrzymanych w pierwszej iteracji bez wzglêdu na $\lambda$ i liczebnoœæ populacji.
\end{enumerate}
\newpage
\subsection{Losowo 10 wybranych punktów w kuli jednostkowej o œrodku w punkcie (0,0) i podzbiór 3-elementowy}

$X= \{ (0.5, -0.5),\,(0.4, 0.1),\,(-0.9, -0.1),\,(0.1, 
   0.12),\,(-0.32, 0.14),\,(-0.1,
   0.58),$ \\ \indent$\,(0.911, 0.2),\,(-0.77, 0.58),\,(0.14, -0.85),\,(-0.14, -0.13)\}$
   \begin{enumerate}
   \item[m = 3,]
    maksimum rzeczywiste $\simeq$4.721 (dla punktów $(0.911,0.2),\,(-0.77,0.58),\,(0.14,-0.85)$ ) 
\begin{table}[h!]
\caption{Wyniki testów na $Max Diversity$ dla punktów kuli ($m=3$)}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}\hline
  & \multicolumn{12}{|c|}{\textit{Iloœæ iteracji}}\\ \cline{2-13}
\textbf{Liczebnoœæ} & \multicolumn{2}{|c|}{} & \multicolumn{10}{|c|}{\textit{PBIL}} \\ \cline{4-13}
\textbf{populacji} &\multicolumn{2}{|c|}{cGA} &    \multicolumn{2}{|c|}{$\lambda = 0.5$} &\multicolumn{2}{|c|}{$\lambda = 0.2$} &\multicolumn{2}{|c|}{$\lambda = 0.1$} &\multicolumn{2}{|c|}{$\lambda = 0.01$} &\multicolumn{2}{|c|}{$\lambda = 0.0001$ } \\\hline\hline 
 3&28.5&77\%  &77.41 &24\%  &39.07 &68 \%  &23.26&92\%  &27.99 &99\%  &  33.55 &93\% \\\hline
 5&11.78&94\%  &65.25 &40\%   &26.57 &81\%  &  14.25&100\%  &17.31&100\%  & 25.59 &98\% \\\hline
 20 &5.51&100\%  & 12.43&91 \%  & 4.55&100\%  &5.5 &100\% &7.17&100\%  &6.63&100\%   \\\hline
 50 &3.72&100\%   &2.84& 100\%    &3.2&100\%   & 3.37 &100\%& 4.12&100\% & 4.12&100\%  \\\hline
 100 &2.79&100\%   &2.54&100 \%    & 2.46 &100\% & 2.68 &100\% &2.67&100\%  &2.91&100\%  \\\hline
\end{tabular}
\end{table}\\
\textbf{Wnioski:} Jeœli rozwa¿amy wystêpowanie b³êdów, algorytm cGA zwraca poprawne wyniki dla mniejszej liczebnoœci populacji. Porównuj¹c czas pracy algorytmów, mo¿na zauwa¿yæ, ¿e cGA zwraca rezultat w krótszym czasie ni¿ PBIL. Zarówno wysoki, jak i bardzo niski wskaŸnik uczenia siê  algorytmu PBIL znacznie zmniejsza efektywnoœæ pracy algorytmu. Dodatkowo wskaŸnik rzêdu 0.5 powoduje wzrost czêstotliwoœci wyst¹pienia b³êdu w obliczeniach. Najbardziej optymaln¹ wartoœci¹ wspó³czynnika uczenia siê okaza³a siê wartoœæ $0.1$, dla której rezultaty cGA i PBIL s¹ zbli¿one
\end{enumerate}
\end{document}
